# -*- coding: utf-8 -*-
"""Cancer_cell_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16CpwpDbilklkz1uXQ8n2BitQk7QTP4e5
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from tensorflow import keras
# %matplotlib inline
import numpy as np
import pickle
import cv2
from os import listdir
from sklearn.preprocessing import LabelBinarizer
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
import keras
from keras.models import *
from keras.layers import *

class MyCustomCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}): 
        if(logs.get('acc') >= 0.96):   
            print("Reached 95% accuracy so cancelling training!")
            self.model.stop_training = True

EPOCHS = 50
INIT_LR = 3e-3
BS =32
default_image_size = tuple((256, 256))
image_size = 0
width=256
height=256
depth=3
train_dir=r"D:\DP\Single_fifteen\Train"

train_folder=listdir(train_dir)

def convert_image_to_array(image_dir):
    try:
        image = cv2.imread(image_dir)
        if image is not None :
            image = cv2.resize(image, default_image_size)   
            return img_to_array(image)
        else :
            return np.array([])
    except Exception as e:
        print(f"Error : {e}")
        return None

callbacks = MyCustomCallback()

train_image_list, train_image_label= [], []
for leuk_folder in train_folder:
    print(f"processing {leuk_folder} ...")
    leuk_img_folder= listdir(f"{train_dir}/{leuk_folder}")
    
    for leuk_img in leuk_img_folder:
       
        image_directory = f"{train_dir}/{leuk_folder}/{leuk_img}"
        if image_directory.endswith(".tiff") == True or image_directory.endswith(".TIFF") == True or  image_directory.endswith(".png") == True:
            train_image_list.append(convert_image_to_array(image_directory))
            train_image_label.append(leuk_folder)
print("[INFO] Image loading completed")

print(len(train_image_label))

label_binarizer = LabelBinarizer()
bin_train_image_labels = label_binarizer.fit_transform(train_image_label)
#bin_valid_image_labels = label_binarizer.fit_transform(valid_image_label)
pickle.dump(label_binarizer,open('Label_Instance_cancer_cell_new.pk', 'wb'))
n_classes = len(label_binarizer.classes_)

print(len(bin_train_image_labels))

print(len(bin_train_image_labels))

np_train_image_list = np.array(train_image_list, dtype=np.float32) / 255.0

print(len(np_train_image_list))

model1 = Sequential()
model1.add(Conv2D(input_shape=(256,256,3),filters=3,kernel_size=(3,3),padding="same", activation="relu"))
model1.add(Conv2D(filters=16,kernel_size=(3,3),padding="same", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=32, kernel_size=(3,3), padding="same", activation="relu"))

model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu"))

model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))

model1.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model1.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))

model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))

model1.add(Flatten())

model2 = Sequential()
model2.add(Conv2D(input_shape=(256,256,3),filters=3,kernel_size=(3,3),padding="same", activation="relu"))
model2.add(Conv2D(filters=16,kernel_size=(3,3),padding="same", activation="relu"))
model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model2.add(Conv2D(filters=32, kernel_size=(3,3), padding="same", activation="relu"))

model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model2.add(Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu"))

model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model2.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))

model2.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model2.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))

model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))

model2.add(Flatten())

model3 = Sequential()
model3.add(Conv2D(input_shape=(256,256,3),filters=3,kernel_size=(3,3),padding="same", activation="relu"))
model3.add(Conv2D(filters=16,kernel_size=(3,3),padding="same", activation="relu"))
model3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model3.add(Conv2D(filters=32, kernel_size=(3,3), padding="same", activation="relu"))

model3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model3.add(Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu"))

model3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model3.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))

model3.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model3.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))

model3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))

model3.add(Flatten())

merged_model = Concatenate()([model1.output,model2.output,model3.output])

x = Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(merged_model)


output = Dense(15, activation='softmax')(x)

opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)

model.compile(loss="categorical_crossentropy", optimizer=opt,metrics=["accuracy"])

print("[INFO] training network...")

from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score,classification_report 
from sklearn.metrics import precision_score 
from sklearn.metrics import recall_score 
from sklearn.metrics import f1_score 
from sklearn.metrics import cohen_kappa_score 
from sklearn.metrics import roc_auc_score 
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import Normalizer

conf_matrix_list_of_arrays = []
#loss_per_fold = []
seed = 13   # for reproducibility you can change it. 
np.random.seed(seed)
kfold = KFold(5, True, seed)
for train_idx, val_idx in kfold.split(np_train_image_list, y=bin_train_image_labels):
    #print('train: %s, val: %s' % (train_idx, val_idx))
    x_train, x_val = np_train_image_list[train_idx], np_train_image_list[val_idx]
    y_train, y_val = bin_train_image_labels[train_idx], bin_train_image_labels[val_idx]
    history=model.fit(x_train, y_train,
                  validation_data=(x_val, y_val),
                  batch_size=BS,
                  epochs=EPOCHS, verbose=1        
                  )
    ycalculated = model.predict(x_val)
    yhat_classes =np.argmax(ycalculated,axis=1)
    rounded_labels=np.argmax(y_val,axis=1)                           
    conf_matrix = confusion_matrix(rounded_labels,yhat_classes)
    conf_matrix_list_of_arrays .append(conf_matrix)

model.save("model_cancer_single_new.h5")

